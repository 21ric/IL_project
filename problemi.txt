RICCARDO:
-Non capisco bene come modificare l'input size della rete. Nonostante le dimensioni diverse il programma parte e funziona
ma non credo che legga le immagini correttamente
-Per ora l'ordine delle classi è fisso e sequenziale, in seguito: randomizzare in modo replicabile
-Il paper dice di fare L2 normalization su i vettori e su qualsiasi vettore risultante da operazioni su questi
per ora non l'ho fatto

LAURA:



LINDA:
- TODO: architettura resnet 
> Ric-(già discusso)

- nel fine tuning è giusto lavorare sempre sulla stessa rete? non dovremmo aggiungere 10 nodi
alla fine di ogni iterazione? 
Come l'abbiamo implementato è finetuning si, ma non in un approccio multi-class..
> Ric - Riga 180 fine-tuning, già era fatto

- LwF iplementation in iCarL paper?? che differenze ci sono??

- TODO: implementare validation in LwF

- TODO: classi splittate randomicamente. *** Stesso split per ogni metodo *** Una soluzione potrebbe essere fare lo split direttamente nel file in CoLab, poi chiamare i vari main in modo sequenziale
